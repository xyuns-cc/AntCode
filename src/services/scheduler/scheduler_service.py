# src/services/scheduler_service.py (æ›´æ–°ç‰ˆæœ¬)
"""ä»»åŠ¡è°ƒåº¦æœåŠ¡"""
import asyncio
import uuid
from datetime import datetime, timezone, timedelta

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.jobstores.base import JobLookupError
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.date import DateTrigger
from apscheduler.triggers.interval import IntervalTrigger
from loguru import logger

from src.core.config import settings
from src.models.enums import TaskStatus, ScheduleType, ProjectType
from src.models.scheduler import ScheduledTask, TaskExecution
from src.services.logs.task_log_service import task_log_service  # æ–°å¢ž
from src.services.projects.relation_service import relation_service  # æ–°å¢ž
from src.services.monitoring import monitoring_service
from src.services.scheduler.spider_dispatcher import spider_task_dispatcher
from src.services.scheduler.task_executor import TaskExecutor


class SchedulerService:
    """è°ƒåº¦å™¨æœåŠ¡"""

    def __init__(self):
        self.scheduler = AsyncIOScheduler(
            timezone=settings.SCHEDULER_TIMEZONE,
            job_defaults={
                'coalesce': True,  # åˆå¹¶é”™è¿‡çš„æ‰§è¡Œ
                'max_instances': 3,  # æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§å¹¶å‘å®žä¾‹æ•°
                'misfire_grace_time': 30  # é”™è¿‡æ‰§è¡Œçš„å®½é™æ—¶é—´ï¼ˆç§’ï¼‰
            }
        )
        self.executor = TaskExecutor()
        self.running_tasks = {}
        
        # å¹¶å‘æŽ§åˆ¶ - é™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°é‡
        self.concurrency_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_TASKS)
        self.task_execution_stats = {
            "total_executed": 0,
            "currently_running": 0,
            "failed_count": 0,
            "success_count": 0
        }

    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        try:
            self.scheduler.start()
            logger.info("âœ… ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")

            # åŠ è½½å·²å­˜åœ¨çš„æ´»è·ƒä»»åŠ¡
            await self._load_active_tasks()
            
            # æ·»åŠ å®šæœŸæ¸…ç†å·¥ä½œç›®å½•çš„ä»»åŠ¡
            await self._add_cleanup_job()

            # æ³¨å†Œç›‘æŽ§ç›¸å…³çš„å‘¨æœŸä»»åŠ¡
            await self._add_monitoring_jobs()

        except Exception as e:
            logger.error(f"å¯åŠ¨è°ƒåº¦å™¨å¤±è´¥: {e}")
            raise

    async def create_task(self, task_data, project_type, user_id):
        """åˆ›å»ºè°ƒåº¦ä»»åŠ¡"""
        try:
            # åˆ›å»ºä»»åŠ¡
            task = await ScheduledTask.create(
                **task_data.model_dump(exclude={'project_id'}),
                project_id=task_data.project_id,
                task_type=project_type,
                user_id=user_id
            )

            # æ·»åŠ åˆ°è°ƒåº¦å™¨
            if task.is_active:
                await self.add_task(task)

            logger.info(f"ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task.name} (ID: {task.id})")
            return task
            
        except Exception as e:
            logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def get_user_tasks(
        self,
        user_id,
        status = None,
        is_active = None,
        page = 1,
        size = 20
    ):
        """èŽ·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨ï¼ˆåŒ…å«åˆ›å»ºè€…ä¿¡æ¯ï¼‰"""
        try:
            from src.services.users.user_service import user_service
            
            # å¦‚æžœuser_idä¸ºNoneï¼Œè¡¨ç¤ºç®¡ç†å‘˜æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
            if user_id is None:
                query = ScheduledTask.all()
            else:
                query = ScheduledTask.filter(user_id=user_id)
            
            if status is not None:
                query = query.filter(status=status)
            if is_active is not None:
                query = query.filter(is_active=is_active)
            
            total = await query.count()
            offset = (page - 1) * size
            tasks = await query.offset(offset).limit(size).order_by('-created_at')
            
            # èŽ·å–åˆ›å»ºè€…ç”¨æˆ·åä¿¡æ¯
            user_ids = list(set([t.user_id for t in tasks]))
            users_map = {}
            if user_ids:
                users = await user_service.get_users_by_ids(user_ids)
                users_map = {user.id: user.username for user in users}
            
            # ä¸ºä»»åŠ¡æ·»åŠ åˆ›å»ºè€…ç”¨æˆ·å
            for task in tasks:
                task.created_by = task.user_id
                task.created_by_username = users_map.get(task.user_id)
            
            return {
                "tasks": tasks,
                "total": total,
                "page": page,
                "size": size,
                "pages": (total + size - 1) // size
            }
        except Exception as e:
            logger.error(f"èŽ·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            raise

    async def get_task_by_id(self, task_id, user_id):
        """æ ¹æ®IDèŽ·å–ä»»åŠ¡"""
        from src.services.users.user_service import user_service
        
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                return None
                
            # èŽ·å–åˆ›å»ºè€…ç”¨æˆ·å
            creator = await user_service.get_user_by_id(task.user_id)
            task.created_by = task.user_id
            task.created_by_username = creator.username if creator else None
            
            return task
        except Exception as e:
            logger.error(f"èŽ·å–ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def update_task(self, task_id, task_data, user_id):
        """æ›´æ–°ä»»åŠ¡"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥æ›´æ–°æ‰€æœ‰ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½æ›´æ–°è‡ªå·±çš„ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                return None
                
            # æ›´æ–°å­—æ®µ
            update_data = task_data.model_dump(exclude_unset=True)
            for field, value in update_data.items():
                setattr(task, field, value)
            
            await task.save()
            
            # å¦‚æžœä»»åŠ¡çŠ¶æ€æ”¹å˜ï¼Œæ›´æ–°è°ƒåº¦å™¨
            if 'is_active' in update_data:
                if task.is_active:
                    await self.add_task(task)
                else:
                    await self.remove_task(task_id)
            
            logger.info(f"ä»»åŠ¡æ›´æ–°æˆåŠŸ: {task.name} (ID: {task.id})")
            return task
            
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def delete_task(self, task_id, user_id):
        """åˆ é™¤ä»»åŠ¡"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥åˆ é™¤æ‰€æœ‰ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½åˆ é™¤è‡ªå·±çš„ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                return False
            
            # ä»Žè°ƒåº¦å™¨ç§»é™¤ï¼ˆä½œä¸šä¸å­˜åœ¨æ—¶ä¸æŠ¥é”™ï¼‰
            await self.remove_task(task_id)
            
            # åˆ é™¤æ•°æ®åº“è®°å½•
            await task.delete()
            
            logger.info(f"ä»»åŠ¡åˆ é™¤æˆåŠŸ: {task.name} (ID: {task.id})")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def get_task_executions(
        self,
        task_id,
        user_id,
        status = None,
        start_date = None,
        end_date = None,
        page = 1,
        size = 20
    ):
        """èŽ·å–ä»»åŠ¡æ‰§è¡Œè®°å½•"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡çš„æ‰§è¡Œè®°å½•
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±ä»»åŠ¡çš„æ‰§è¡Œè®°å½•
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®")
            
            query = TaskExecution.filter(task_id=task_id)
            
            if status is not None:
                query = query.filter(status=status)
            if start_date:
                query = query.filter(start_time__gte=start_date)
            if end_date:
                query = query.filter(start_time__lte=end_date)
            
            total = await query.count()
            offset = (page - 1) * size
            executions = await query.offset(offset).limit(size).order_by('-start_time')
            
            return {
                "executions": executions,
                "total": total,
                "page": page,
                "size": size,
                "pages": (total + size - 1) // size
            }
        except Exception as e:
            logger.error(f"èŽ·å–ä»»åŠ¡æ‰§è¡Œè®°å½•å¤±è´¥: {e}")
            raise

    async def get_execution_by_id(self, execution_id):
        """æ ¹æ®IDèŽ·å–æ‰§è¡Œè®°å½•"""
        try:
            return await TaskExecution.get_or_none(execution_id=execution_id)
        except Exception as e:
            logger.error(f"èŽ·å–æ‰§è¡Œè®°å½•å¤±è´¥: {e}")
            raise

    async def get_task_stats(self, task_id, user_id):
        """èŽ·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±ä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                return None
                
            # èŽ·å–æ‰§è¡Œç»Ÿè®¡
            executions = await TaskExecution.filter(task_id=task_id).all()
            
            total = len(executions)
            if total == 0:
                return {
                    "task_id": task_id,
                    "total_executions": 0,
                    "success_count": 0,
                    "failed_count": 0,
                    "running_count": 0,
                    "success_rate": 0.0,
                    "avg_duration": 0.0,
                    "last_execution": None
                }
            
            success_count = sum(1 for e in executions if e.status == TaskStatus.SUCCESS)
            failed_count = sum(1 for e in executions if e.status == TaskStatus.FAILED) 
            running_count = sum(1 for e in executions if e.status == TaskStatus.RUNNING)
            
            # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é•¿
            completed_executions = [e for e in executions if e.end_time and e.start_time]
            avg_duration = 0.0
            if completed_executions:
                durations = [(e.end_time - e.start_time).total_seconds() for e in completed_executions]
                avg_duration = sum(durations) / len(durations)
            
            # èŽ·å–æœ€åŽæ‰§è¡Œ
            last_execution = max(executions, key=lambda e: e.start_time) if executions else None
            
            return {
                "task_id": task_id,
                "total_executions": total,
                "success_count": success_count,
                "failed_count": failed_count,
                "running_count": running_count,
                "success_rate": success_count / total * 100,
                "avg_duration": avg_duration,
                "last_execution": {
                    "execution_id": last_execution.execution_id,
                    "status": last_execution.status,
                    "start_time": last_execution.start_time,
                    "end_time": last_execution.end_time
                } if last_execution else None
            }
        except Exception as e:
            logger.error(f"èŽ·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            raise

    async def verify_admin_permission(self, user_id):
        """éªŒè¯ç®¡ç†å‘˜æƒé™"""
        try:
            from src.models.user import User
            user = await User.get_or_none(id=user_id)
            return user and user.is_admin
        except Exception as e:
            logger.error(f"éªŒè¯ç®¡ç†å‘˜æƒé™å¤±è´¥: {e}")
            return False

    async def get_user_task_ids(self, user_id):
        """èŽ·å–ç”¨æˆ·æ‰€æœ‰ä»»åŠ¡IDåˆ—è¡¨"""
        try:
            tasks = await ScheduledTask.filter(user_id=user_id).all()
            return [task.id for task in tasks]
        except Exception as e:
            logger.error(f"èŽ·å–ç”¨æˆ·ä»»åŠ¡IDå¤±è´¥: {e}")
            return []

    async def get_task_executions_by_task_ids(self, task_ids):
        """æ ¹æ®ä»»åŠ¡IDåˆ—è¡¨èŽ·å–æ‰€æœ‰æ‰§è¡Œè®°å½•"""
        try:
            if not task_ids:
                return []
            return await TaskExecution.filter(task_id__in=task_ids).all()
        except Exception as e:
            logger.error(f"èŽ·å–ä»»åŠ¡æ‰§è¡Œè®°å½•å¤±è´¥: {e}")
            return []

    async def pause_task_by_user(self, task_id, user_id):
        """æš‚åœç”¨æˆ·ä»»åŠ¡"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥æš‚åœæ‰€æœ‰ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½æš‚åœè‡ªå·±çš„ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                return False
            
            try:
                await self.pause_task(task_id)
            except ValueError:
                return False
            return True
        except Exception as e:
            logger.error(f"æš‚åœä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def resume_task_by_user(self, task_id, user_id):
        """æ¢å¤ç”¨æˆ·ä»»åŠ¡"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥æ¢å¤æ‰€æœ‰ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½æ¢å¤è‡ªå·±çš„ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                return False
            
            try:
                await self.resume_task(task_id)
            except ValueError:
                return False
            return True
        except Exception as e:
            logger.error(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def trigger_task_by_user(self, task_id, user_id):
        """ç«‹å³è§¦å‘ç”¨æˆ·ä»»åŠ¡"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥è§¦å‘æ‰€æœ‰ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id)
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½è§¦å‘è‡ªå·±çš„ä»»åŠ¡
                task = await ScheduledTask.get_or_none(id=task_id, user_id=user_id)
                
            if not task:
                return False
            
            await self.trigger_task(task_id)
            return True
        except Exception as e:
            logger.error(f"è§¦å‘ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def get_execution_with_permission(self, execution_id, user_id):
        """èŽ·å–æ‰§è¡Œè®°å½•ï¼ˆå¸¦æƒé™éªŒè¯ï¼‰"""
        try:
            execution = await TaskExecution.get_or_none(execution_id=execution_id)
            if not execution:
                return None
                
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜
            is_admin = await self.verify_admin_permission(user_id)
            
            if is_admin:
                # ç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰æ‰§è¡Œè®°å½•
                return execution
            else:
                # æ™®é€šç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±ä»»åŠ¡çš„æ‰§è¡Œè®°å½•
                task = await ScheduledTask.get_or_none(id=execution.task_id, user_id=user_id)
                if not task:
                    return None
                    
                return execution
        except Exception as e:
            logger.error(f"èŽ·å–æ‰§è¡Œè®°å½•å¤±è´¥: {e}")
            raise

    async def shutdown(self):
        """å…³é—­è°ƒåº¦å™¨"""
        try:
            self.scheduler.shutdown(wait=True)
            logger.info("ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­è°ƒåº¦å™¨å¤±è´¥: {e}")

    async def _load_active_tasks(self):
        """åŠ è½½æ´»è·ƒä»»åŠ¡"""
        try:
            active_tasks = await ScheduledTask.filter(is_active=True).all()
            for task in active_tasks:
                await self.add_task(task)
                logger.info(f"åŠ è½½ä»»åŠ¡: {task.name}")
        except Exception as e:
            logger.error(f"åŠ è½½æ´»è·ƒä»»åŠ¡å¤±è´¥: {e}")

    async def add_task(self, task):
        """æ·»åŠ ä»»åŠ¡åˆ°è°ƒåº¦å™¨"""
        try:
            # åˆ›å»ºè§¦å‘å™¨
            trigger = self._create_trigger(task)

            # æ·»åŠ ä½œä¸š
            self.scheduler.add_job(
                func=self._execute_task,
                trigger=trigger,
                id=str(task.id),
                name=task.name,
                kwargs={'task_id': task.id},
                replace_existing=True
            )

            logger.info(f"âœ… ä»»åŠ¡ {task.name} å·²æ·»åŠ åˆ°è°ƒåº¦å™¨")

        except Exception as e:
            logger.error(f"æ·»åŠ ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def remove_task(self, task_id):
        """ä»Žè°ƒåº¦å™¨ç§»é™¤ä»»åŠ¡"""
        try:
            self.scheduler.remove_job(str(task_id))
            logger.info(f"ä»»åŠ¡ {task_id} å·²ä»Žè°ƒåº¦å™¨ç§»é™¤")
        except JobLookupError:
            logger.warning(f"ä»»åŠ¡ {task_id} åœ¨è°ƒåº¦å™¨ä¸­ä¸å­˜åœ¨ï¼Œè§†ä¸ºå·²ç§»é™¤")
        except Exception as e:
            logger.error(f"ç§»é™¤ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def pause_task(self, task_id):
        """æš‚åœä»»åŠ¡"""
        try:
            self.scheduler.pause_job(str(task_id))

            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            task = await ScheduledTask.get(id=task_id)
            task.status = TaskStatus.PAUSED
            task.is_active = False
            await task.save()

            logger.info(f"ä»»åŠ¡ {task_id} å·²æš‚åœ")
        except JobLookupError:
            logger.warning(f"ä»»åŠ¡ {task_id} åœ¨è°ƒåº¦å™¨ä¸­ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²æ‰§è¡Œå®Œæˆæˆ–æœªæ¿€æ´»ï¼Œæ— æ³•æš‚åœ")
            raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²æ‰§è¡Œå®Œæˆï¼Œæ— æ³•æš‚åœ")
        except Exception as e:
            logger.error(f"æš‚åœä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def resume_task(self, task_id):
        """æ¢å¤ä»»åŠ¡"""
        try:
            self.scheduler.resume_job(str(task_id))

            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            task = await ScheduledTask.get(id=task_id)
            task.status = TaskStatus.PENDING
            task.is_active = True
            await task.save()

            logger.info(f"ä»»åŠ¡ {task_id} å·²æ¢å¤")
        except JobLookupError:
            logger.warning(f"ä»»åŠ¡ {task_id} åœ¨è°ƒåº¦å™¨ä¸­ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²æ‰§è¡Œå®Œæˆæˆ–æœªæ¿€æ´»ï¼Œæ— æ³•æ¢å¤")
            raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²æ‰§è¡Œå®Œæˆï¼Œæ— æ³•æ¢å¤")
        except Exception as e:
            logger.error(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def trigger_task(self, task_id):
        """ç«‹å³è§¦å‘ä»»åŠ¡"""
        try:
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨äºŽè°ƒåº¦å™¨ä¸­
            job = self.scheduler.get_job(str(task_id))
            if job:
                # å¦‚æžœå­˜åœ¨ï¼Œä¿®æ”¹ä¸‹æ¬¡è¿è¡Œæ—¶é—´ä¸ºçŽ°åœ¨
                try:
                    aware_now = datetime.now(self.scheduler.timezone)
                except Exception:
                    aware_now = datetime.now(timezone.utc)
                job.modify(next_run_time=aware_now)
                logger.info(f"ä»»åŠ¡ {task_id} å·²è§¦å‘")
            else:
                # å¦‚æžœä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªä¸´æ—¶ä½œä¸šæ¥æ‰§è¡Œ
                logger.info(f"ä»»åŠ¡ {task_id} ä¸åœ¨è°ƒåº¦å™¨ä¸­ï¼Œåˆ›å»ºä¸´æ—¶ä½œä¸šæ‰§è¡Œ")
                
                # ä½¿ç”¨å”¯ä¸€çš„job_idï¼ŒåŒ…å«æ—¶é—´æˆ³é¿å…å†²çª
                temp_job_id = f"{task_id}_manual_{datetime.now().timestamp()}"
                
                # æ·»åŠ ä¸€ä¸ªç«‹å³æ‰§è¡Œçš„ä½œä¸š
                self.scheduler.add_job(
                    func=self._execute_task,
                    trigger=DateTrigger(
                        run_date=(datetime.now(self.scheduler.timezone) if hasattr(self.scheduler, 'timezone') and self.scheduler.timezone else datetime.now(timezone.utc))
                    ),
                    id=temp_job_id,
                    kwargs={'task_id': task_id},
                    replace_existing=True
                )
        except Exception as e:
            logger.error(f"è§¦å‘ä»»åŠ¡å¤±è´¥: {e}")
            raise

    def _create_trigger(self, task):
        """åˆ›å»ºè§¦å‘å™¨"""
        if task.schedule_type == ScheduleType.CRON:
            return CronTrigger.from_crontab(task.cron_expression)
        elif task.schedule_type == ScheduleType.INTERVAL:
            return IntervalTrigger(seconds=task.interval_seconds)
        elif task.schedule_type == ScheduleType.DATE:
            return DateTrigger(run_date=task.scheduled_time)
        elif task.schedule_type == ScheduleType.ONCE:
            return DateTrigger(run_date=task.scheduled_time or datetime.now())
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è°ƒåº¦ç±»åž‹: {task.schedule_type}")

    async def _execute_task(self, task_id):
        """æ‰§è¡Œä»»åŠ¡çš„æ ¸å¿ƒæ–¹æ³•ï¼ˆå¸¦å¹¶å‘æŽ§åˆ¶ï¼‰"""
        # ä½¿ç”¨ä¿¡å·é‡æŽ§åˆ¶å¹¶å‘æ•°
        async with self.concurrency_semaphore:
            await self._execute_task_internal(task_id)
    
    async def _execute_task_internal(self, task_id):
        """æ‰§è¡Œä»»åŠ¡çš„å†…éƒ¨å®žçŽ°"""
        execution_id = str(uuid.uuid4())
        task = None
        execution = None

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.task_execution_stats["total_executed"] += 1
        self.task_execution_stats["currently_running"] += 1

        try:
            # èŽ·å–ä»»åŠ¡åŠå…¶å…³è”ä¿¡æ¯
            task_info = await relation_service.get_task_with_project(task_id)
            if not task_info:
                logger.error(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
                return

            task = task_info["task"]
            project = task_info["project"]
            project_detail = task_info["project_detail"]

            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å¯ä»¥æ‰§è¡Œ
            if not task.is_active:
                logger.warning(f"ä»»åŠ¡ {task.name} æœªæ¿€æ´»ï¼Œè·³è¿‡æ‰§è¡Œ")
                return
                
            # è®°å½•å¹¶å‘çŠ¶æ€
            current_running = self.task_execution_stats["currently_running"]
            max_concurrent = settings.MAX_CONCURRENT_TASKS
            logger.info(f"ðŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡ {task.name} (å½“å‰å¹¶å‘: {current_running}/{max_concurrent})")

            # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶è·¯å¾„
            log_paths = task_log_service.generate_log_paths(execution_id, task.name)

            # åˆ›å»ºæ‰§è¡Œè®°å½•
            now = datetime.now(timezone.utc)
            execution = await TaskExecution.create(
                execution_id=execution_id,
                task_id=task.id,  # åº”ç”¨å±‚å¤–é”®
                status=TaskStatus.RUNNING,
                start_time=now,
                log_file_path=log_paths["log_file_path"],
                error_log_path=log_paths["error_log_path"],
                retry_count=0
            )

            # ç¡®ä¿æ‰§è¡Œè®°å½•å·²ä¿å­˜åˆ°æ•°æ®åº“
            await execution.save()

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = TaskStatus.RUNNING
            task.last_run_time = now
            await task.save()

            # è®°å½•åˆ°è¿è¡Œä¸­ä»»åŠ¡
            self.running_tasks[execution_id] = {
                'task_id': task_id,
                'task_name': task.name,
                'start_time': now
            }

            # æŽ¨é€å¼€å§‹çŠ¶æ€åˆ°WebSocket
            await self._push_execution_status(execution, {
                "status": "RUNNING",
                "message": "ä»»åŠ¡å¼€å§‹æ‰§è¡Œ",
                "task_name": task.name,
                "start_time": now.isoformat()
            })

            # è®°å½•æ—¥å¿—
            await self._log_execution(
                execution,
                "INFO",
                f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.name}"
            )

            # æ ¹æ®é¡¹ç›®ç±»åž‹æ‰§è¡Œä¸åŒçš„é€»è¾‘
            if project.type == ProjectType.RULE:
                # è§„åˆ™é¡¹ç›®ï¼šæäº¤åˆ°Redis
                result = await self._execute_rule_task(task, project, project_detail, execution)
            else:
                # æ–‡ä»¶/ä»£ç é¡¹ç›®ï¼šæœ¬åœ°æ‰§è¡Œ
                result = await self.executor.execute(
                    project=project,
                    execution_id=execution_id,
                    params=task.execution_params,
                    environment_vars=task.environment_vars,
                    timeout=task.timeout_seconds or settings.TASK_EXECUTION_TIMEOUT
                )

            # å¤„ç†æ‰§è¡Œç»“æžœ
            if result.get('success'):
                execution.status = TaskStatus.SUCCESS
                execution.result = result
                task.status = TaskStatus.SUCCESS
                task.success_count += 1

                # ä¿å­˜æ—¥å¿—æ–‡ä»¶è·¯å¾„
                if result.get('log_file_path'):
                    execution.log_file_path = result['log_file_path']
                if result.get('error_log_path'):
                    execution.error_log_path = result['error_log_path']

                await self._log_execution(
                    execution,
                    "INFO",
                    f"ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ: {result.get('message', 'æ‰§è¡Œå®Œæˆ')}"
                )

                # æŽ¨é€æˆåŠŸçŠ¶æ€åˆ°WebSocket
                await self._push_execution_status(execution, {
                    "status": "SUCCESS",
                    "message": "ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ",
                    "result": result
                })
            else:
                execution.status = TaskStatus.FAILED
                execution.error_message = result.get('error')
                task.status = TaskStatus.FAILED
                task.failure_count += 1

                # ä¿å­˜æ—¥å¿—æ–‡ä»¶è·¯å¾„
                if result.get('log_file_path'):
                    execution.log_file_path = result['log_file_path']
                if result.get('error_log_path'):
                    execution.error_log_path = result['error_log_path']

                await self._log_execution(
                    execution,
                    "ERROR",
                    f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {result.get('error')}"
                )

                # æŽ¨é€å¤±è´¥çŠ¶æ€åˆ°WebSocket
                await self._push_execution_status(execution, {
                    "status": "FAILED",
                    "message": "ä»»åŠ¡æ‰§è¡Œå¤±è´¥",
                    "error": result.get('error')
                })

                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                if task.retry_count > 0 and execution.retry_count < task.retry_count:
                    await self._schedule_retry(task, execution)

        except asyncio.TimeoutError:
            if execution:
                execution.status = TaskStatus.TIMEOUT
                execution.error_message = "ä»»åŠ¡æ‰§è¡Œè¶…æ—¶"
            if task:
                task.status = TaskStatus.TIMEOUT
                task.failure_count += 1

            await self._log_execution(
                execution,
                "ERROR",
                "ä»»åŠ¡æ‰§è¡Œè¶…æ—¶"
            )

        except Exception as e:
            logger.error(f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            if execution:
                execution.status = TaskStatus.FAILED
                execution.error_message = str(e)
            if task:
                task.status = TaskStatus.FAILED
                task.failure_count += 1

            await self._log_execution(
                execution,
                "ERROR",
                f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            )

        finally:
            # æ›´æ–°å¹¶å‘ç»Ÿè®¡
            self.task_execution_stats["currently_running"] -= 1
            
            # æ›´æ–°æˆåŠŸ/å¤±è´¥ç»Ÿè®¡
            if execution and execution.status == TaskStatus.SUCCESS:
                self.task_execution_stats["success_count"] += 1
            elif execution and execution.status == TaskStatus.FAILED:
                self.task_execution_stats["failed_count"] += 1
            
            # æ¸…ç†è¿è¡Œä¸­ä»»åŠ¡
            if execution_id in self.running_tasks:
                del self.running_tasks[execution_id]

            # æ›´æ–°æ‰§è¡Œè®°å½•
            if execution:
                execution.end_time = datetime.now(timezone.utc)
                if execution.start_time:
                    execution.duration_seconds = (
                            execution.end_time - execution.start_time
                    ).total_seconds()
                await execution.save()

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            if task:
                if task.status == TaskStatus.RUNNING:
                    task.status = TaskStatus.PENDING
                task.next_run_time = self._get_next_run_time(task_id)
                await task.save()
                
            # è®°å½•ä»»åŠ¡å®ŒæˆçŠ¶æ€
            current_running = self.task_execution_stats["currently_running"]
            max_concurrent = settings.MAX_CONCURRENT_TASKS
            logger.info(f"âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ (å½“å‰å¹¶å‘: {current_running}/{max_concurrent})")

    async def _execute_rule_task(
            self,
            task,
            project,
            rule_detail,
            execution
    ):
        """æ‰§è¡Œè§„åˆ™ä»»åŠ¡ - æ ¹æ®é…ç½®é€‰æ‹©æ‰§è¡Œå™¨"""
        try:
            if not rule_detail:
                return {
                    "success": False,
                    "error": "è§„åˆ™é¡¹ç›®è¯¦æƒ…ä¸å­˜åœ¨"
                }

            # å‡†å¤‡å‚æ•°
            params = task.execution_params or {}
            params["scheduled_task_id"] = task.id
            params["scheduled_task_name"] = task.name

            # æ ¹æ®è§„åˆ™é…ç½®å†³å®šæäº¤ç­–ç•¥
            if rule_detail.pagination_config and \
                    rule_detail.pagination_config.get("method") == "url_pattern":
                # URLåˆ†é¡µæ¨¡å¼ï¼šå¯èƒ½éœ€è¦æäº¤å¤šä¸ªä»»åŠ¡
                tasks_submitted = []
                start_page = rule_detail.pagination_config.get("start_page", 1)
                max_pages = rule_detail.pagination_config.get("max_pages", 10)

                for page in range(start_page, start_page + max_pages):
                    page_params = params.copy()
                    page_params["page_number"] = page

                    # æ›¿æ¢URLä¸­çš„é¡µç 
                    original_url = rule_detail.target_url
                    if "{}" in original_url:
                        rule_detail.target_url = original_url.format(page)

                    result = await spider_task_dispatcher.submit_rule_task(
                        project=project,
                        rule_detail=rule_detail,
                        execution_id=f"{execution.execution_id}_page_{page}",
                        params=page_params
                    )

                    rule_detail.target_url = original_url  # æ¢å¤åŽŸURL

                    if result["success"]:
                        tasks_submitted.append(result["task_id"])

                    await self._log_execution(
                        execution,
                        "INFO",
                        f"æäº¤é¡µé¢ {page} åˆ°{result.get('queue', 'local:scrapy')}: {result.get('task_id')}"
                    )

                return {
                    "success": True,
                    "message": f"æˆåŠŸæäº¤ {len(tasks_submitted)} ä¸ªä»»åŠ¡åˆ°æ‰§è¡Œå™¨",
                    "task_ids": tasks_submitted,
                    "total_pages": len(tasks_submitted)
                }
            else:
                # å•ä»»åŠ¡æäº¤
                result = await spider_task_dispatcher.submit_rule_task(
                    project=project,
                    rule_detail=rule_detail,
                    execution_id=execution.execution_id,
                    params=params
                )

                if result["success"]:
                    await self._log_execution(
                        execution,
                        "INFO",
                        f"ä»»åŠ¡å·²æäº¤åˆ°{result.get('queue', 'local:scrapy')}: {result.get('task_id')}"
                    )

                    return {
                        "success": True,
                        "message": f"ä»»åŠ¡å·²æäº¤åˆ°{result.get('queue', 'æœ¬åœ°æ‰§è¡Œå™¨')}",
                        "task_id": result.get("task_id"),
                        "queue": result.get("queue")
                    }
                else:
                    return {
                        "success": False,
                        "error": result.get("message", "æäº¤å¤±è´¥")
                    }

        except Exception as e:
            logger.error(f"æ‰§è¡Œè§„åˆ™ä»»åŠ¡å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    async def _schedule_retry(self, task, execution):
        """è°ƒåº¦é‡è¯•"""
        execution.retry_count += 1
        await execution.save()

        # å»¶è¿ŸåŽé‡è¯•
        retry_delay = task.retry_delay or settings.TASK_RETRY_DELAY
        
        # ä½¿ç”¨å”¯ä¸€çš„job_idï¼ŒåŒ…å«execution_idä»¥é¿å…å†²çª
        job_id = f"{task.id}_retry_{execution.execution_id}_{execution.retry_count}"
        
        # å…ˆå°è¯•ç§»é™¤å¯èƒ½å­˜åœ¨çš„æ—§ä½œä¸š
        try:
            self.scheduler.remove_job(job_id)
        except:
            pass  # å¿½ç•¥ä½œä¸šä¸å­˜åœ¨çš„é”™è¯¯

        try:
            base_time = datetime.now(self.scheduler.timezone) if hasattr(self.scheduler, 'timezone') and self.scheduler.timezone else datetime.now(timezone.utc)
        except Exception:
            base_time = datetime.now(timezone.utc)

        self.scheduler.add_job(
            func=self._execute_task,
            trigger=DateTrigger(
                run_date=base_time + timedelta(seconds=retry_delay)
            ),
            id=job_id,
            kwargs={'task_id': task.id},
            replace_existing=True  # å¦‚æžœå­˜åœ¨åˆ™æ›¿æ¢
        )

        await self._log_execution(
            execution,
            "INFO",
            f"ä»»åŠ¡å°†åœ¨ {retry_delay} ç§’åŽé‡è¯• (ç¬¬{execution.retry_count}æ¬¡)"
        )

    async def _log_execution(
            self,
            execution,
            level,
            message
    ):
        """è®°å½•æ‰§è¡Œæ—¥å¿—"""
        if execution and execution.log_file_path:
            # å†™å…¥æ—¥å¿—æ–‡ä»¶å¹¶å®žæ—¶æŽ¨é€åˆ°WebSocket
            log_content = f"[{level}] {message}"
            if level.upper() in ["ERROR", "CRITICAL"]:
                # é”™è¯¯æ—¥å¿—å†™å…¥é”™è¯¯æ—¥å¿—æ–‡ä»¶
                if execution.error_log_path:
                    await task_log_service.write_log(
                        execution.error_log_path,
                        log_content,
                        execution_id=execution.execution_id
                    )
            else:
                # æ™®é€šæ—¥å¿—å†™å…¥è¾“å‡ºæ—¥å¿—æ–‡ä»¶
                await task_log_service.write_log(
                    execution.log_file_path,
                    log_content,
                    execution_id=execution.execution_id
                )

    async def _push_execution_status(self, execution, status_data):
        """æŽ¨é€æ‰§è¡ŒçŠ¶æ€åˆ°WebSocketå®¢æˆ·ç«¯ï¼ˆå·²ç§»é™¤WebSocketåŠŸèƒ½ï¼‰"""
        # WebSocketåŠŸèƒ½å·²è¢«ç§»é™¤ï¼Œæ­¤æ–¹æ³•ä¿ç•™ä»¥ä¿æŒå…¼å®¹æ€§
        pass

    def _get_next_run_time(self, task_id):
        """èŽ·å–ä¸‹æ¬¡è¿è¡Œæ—¶é—´"""
        job = self.scheduler.get_job(str(task_id))
        if job and job.next_run_time:
            return job.next_run_time
        return None

    def get_running_tasks(self):
        """èŽ·å–è¿è¡Œä¸­çš„ä»»åŠ¡"""
        return list(self.running_tasks.values())
    
    def get_execution_stats(self):
        """èŽ·å–ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.task_execution_stats,
            "success_rate": (
                self.task_execution_stats["success_count"] / 
                max(1, self.task_execution_stats["total_executed"])
            ) * 100,
            "max_concurrent_tasks": settings.MAX_CONCURRENT_TASKS,
            "available_slots": settings.MAX_CONCURRENT_TASKS - self.task_execution_stats["currently_running"]
        }

    async def _add_cleanup_job(self):
        """æ·»åŠ å®šæœŸæ¸…ç†å·¥ä½œç›®å½•çš„ä»»åŠ¡"""
        try:
            # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ¸…ç†
            self.scheduler.add_job(
                func=self._cleanup_workspaces,
                trigger=CronTrigger(hour=2, minute=0),
                id="workspace_cleanup",
                name="æ¸…ç†æ‰§è¡Œå·¥ä½œç›®å½•",
                replace_existing=True
            )
            logger.info("âœ… å·²æ·»åŠ å®šæœŸæ¸…ç†å·¥ä½œç›®å½•ä»»åŠ¡ï¼ˆæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œï¼‰")
        except Exception as e:
            logger.error(f"æ·»åŠ æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}")

    async def _cleanup_workspaces(self):
        """æ‰§è¡Œå·¥ä½œç›®å½•æ¸…ç†"""
        try:
            logger.info("ðŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸçš„æ‰§è¡Œå·¥ä½œç›®å½•...")
            await self.executor.cleanup_old_workspaces(
                max_age_hours=settings.CLEANUP_WORKSPACE_MAX_AGE_HOURS
            )
            logger.info("âœ… å·¥ä½œç›®å½•æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç†å·¥ä½œç›®å½•å¤±è´¥: {e}")

    async def _add_monitoring_jobs(self):
        """æ³¨å†Œç›‘æŽ§æ•°æ®å¤„ç†ä»»åŠ¡"""
        if not settings.MONITORING_ENABLED:
            logger.info("ç›‘æŽ§åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡ç›‘æŽ§ä»»åŠ¡æ³¨å†Œ")
            return

        try:
            self.scheduler.add_job(
                func=self._process_monitoring_stream,
                trigger=IntervalTrigger(seconds=settings.MONITOR_STREAM_INTERVAL),
                id="monitoring_process_stream",
                name="ç›‘æŽ§æ•°æ®æµå¤„ç†",
                replace_existing=True,
            )

            self.scheduler.add_job(
                func=self._cleanup_monitoring_data,
                trigger=CronTrigger(hour=3, minute=30),
                id="monitoring_cleanup_data",
                name="ç›‘æŽ§åŽ†å²æ•°æ®æ¸…ç†",
                replace_existing=True,
            )
            logger.info("âœ… å·²æ³¨å†Œç›‘æŽ§æ•°æ®å¤„ç†ä»»åŠ¡")
        except Exception as e:
            logger.error(f"æ³¨å†Œç›‘æŽ§ä»»åŠ¡å¤±è´¥: {e}")

    async def _process_monitoring_stream(self):
        """å¤„ç†ç›‘æŽ§æ•°æ®æµ"""
        try:
            processed = await monitoring_service.process_stream()
            if processed:
                logger.debug("å¤„ç†ç›‘æŽ§æµæ•°æ® %s æ¡", processed)
        except Exception as e:
            logger.error(f"å¤„ç†ç›‘æŽ§æ•°æ®æµå¤±è´¥: {e}")

    async def _cleanup_monitoring_data(self):
        """æ¸…ç†è¿‡æœŸçš„ç›‘æŽ§åŽ†å²æ•°æ®"""
        try:
            await monitoring_service.cleanup_old_data()
            logger.info("ç›‘æŽ§åŽ†å²æ•°æ®æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç†ç›‘æŽ§åŽ†å²æ•°æ®å¤±è´¥: {e}")


# åˆ›å»ºå…¨å±€è°ƒåº¦å™¨æœåŠ¡å®žä¾‹
scheduler_service = SchedulerService()
